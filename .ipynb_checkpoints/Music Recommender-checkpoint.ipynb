{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# for i, feature in enumerate(audio_feature_cols):\n",
    "#     plt.subplot(4, 4, i+1)\n",
    "#     plt.hist(df[feature])\n",
    "#     plt.title(feature)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "def plot(feat):\n",
    "    plt.figure()\n",
    "    plt.hist(df[feat])\n",
    "    plt.xlabel(feat)\n",
    "    plt.show()\n",
    "\n",
    "audio_feature_cols = ['popularity', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "                          'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature']\n",
    "\n",
    "for feat in audio_feature_cols:\n",
    "    plot(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfe03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features_cols = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                          'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'year', 'popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c0da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    years = []\n",
    "    for date in df['release_date']:\n",
    "        years.append(int(date[:4]))\n",
    "\n",
    "    df['year'] = years\n",
    "    \n",
    "    dropped_cols = ['name', 'artist', 'album', 'key', 'mode', 'time_signature', 'release_date']\n",
    "    return df.drop(dropped_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale_min_max(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "    return pd.DataFrame(scaled_features, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f30ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_standard(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "    return pd.DataFrame(scaled_features, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df, scaler='standard'):\n",
    "    if scaler == 'minmax':\n",
    "        return scale_min_max(df)\n",
    "    elif scaler == 'standard':\n",
    "        return scale_standard(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def apply_PCA(df, n):\n",
    "    pca = PCA(n_components=n)\n",
    "    return pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aefaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, n):\n",
    "    df_cont = clean_df(df)\n",
    "    df_ids = df_cont['id']\n",
    "    df_cont = scale_df(df_cont.drop('id', axis=1), scaler='standard')\n",
    "    pca_arr = apply_PCA(df_cont, n)\n",
    "    pca_df_cols = []\n",
    "    for i in range(len(pca_arr[0])):\n",
    "        pca_df_cols.append('feature {}'.format(i+1))\n",
    "    df_cont = pd.DataFrame(pca_arr, columns=pca_df_cols)\n",
    "    df_cont['id'] = df_ids\n",
    "    return df_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of tuples of tracks and ids sorted by Euclidean distance\n",
    "# precondition: The given track ID is in df.\n",
    "def fit_euclid_dist_recommender(df, given_track_id):\n",
    "    df_cont = preprocess_df(df, 6)\n",
    "    \n",
    "    given_track_df = df_cont.loc[df_cont['id'] == given_track_id]\n",
    "    given_track_array = np.array(given_track_df.drop(['id'], axis=1)).reshape(-1,)\n",
    "        \n",
    "    track_distances = []\n",
    "\n",
    "    for i in range(len(df_cont)):\n",
    "        track_id = df_cont.iloc[i]['id']\n",
    "        track_array = np.array(df_cont.iloc[i].drop(['id']))\n",
    "        euclid_dist = np.linalg.norm(given_track_array - track_array)\n",
    "        track_distances.append((track_id, euclid_dist))\n",
    "\n",
    "    return sorted(track_distances, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0200ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of tuples that contain the song names and IDs of the recommended songs\n",
    "# precondition: num_tracks < len(df)\n",
    "# precondition: closeness >= 0 and closeness <= 1\n",
    "def euclid_dist_recommender(df, sorted_tracks, num_tracks, closeness):\n",
    "    rec_songs = []\n",
    "    starting_index = int(closeness*(len(df)-2))+1\n",
    "    for i in range(num_tracks):\n",
    "        if (i+starting_index >= len(df)):\n",
    "            continue\n",
    "        song_df = df[df['id']==sorted_tracks[i+starting_index][0]]\n",
    "        rec_song = (song_df.iloc[0]['name'], song_df.iloc[0]['id'])\n",
    "        rec_songs.append(rec_song)\n",
    "    \n",
    "    return rec_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name']=='Drag Me Down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcdec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tracks = fit_euclid_dist_recommender(df, '2K87XMYnUMqLcX3zvtAF4G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_songs = euclid_dist_recommender(df, sorted_tracks, 5, 0)\n",
    "print(rec_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(rec_songs):\n",
    "    ids_list = []\n",
    "    for song in rec_songs:\n",
    "        ids_list.append(song[1])\n",
    "    \n",
    "    return ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_closeness(df, given_song_id, rec_songs_id, dims):\n",
    "    df_dims = df[dims+['id']]\n",
    "    \n",
    "    given_row = df_dims.loc[df_dims['id']==given_song_id]\n",
    "    given_point = (given_row.iloc[0][dims[0]], given_row.iloc[0][dims[1]])\n",
    "    \n",
    "    rec_points = []\n",
    "    \n",
    "    for song in rec_songs_id:\n",
    "        row = df_dims.loc[df_dims['id']==song]\n",
    "        point = (row.iloc[0][dims[0]], row.iloc[0][dims[1]])\n",
    "        rec_points.append(point)\n",
    "    \n",
    "    rec_x = [point[0] for point in rec_points]\n",
    "    rec_y = [point[1] for point in rec_points]\n",
    "    \n",
    "    df_other = df_dims[~df_dims['id'].isin(rec_songs_id)]\n",
    "    points = []\n",
    "    \n",
    "    for index in range(len(df_other)):\n",
    "        point = (df_other.iloc[index][0], df_other.iloc[index][1])\n",
    "        points.append(point)\n",
    "    \n",
    "    x = [point[0] for point in points]\n",
    "    y = [point[1] for point in points]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(x, y)\n",
    "    plt.scatter(rec_x, rec_y, c='orange')\n",
    "    plt.scatter(given_point[0], given_point[1], c='red')\n",
    "    plt.xlabel(dims[0])\n",
    "    plt.ylabel(dims[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat_1 in enumerate(continuous_features_cols):\n",
    "    for feat_2 in continuous_features_cols:\n",
    "        if feat_2 == feat_1:\n",
    "            continue\n",
    "        if continuous_features_cols.index(feat_2) < i:\n",
    "            continue\n",
    "        \n",
    "        plot_closeness(df, '7qiZfU4dY1lWllzX7mPBI3', get_ids(rec_songs), [feat_1, feat_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "def init_centroids(feat_range, k, df):\n",
    "    rng = default_rng()\n",
    "    centroids = []\n",
    "    for c in range(k):\n",
    "        centroids.append((c, rng.uniform(low=feat_range[0], high=feat_range[1], size=len(df.columns)-1)))\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary containing the track centroids and lables after clustering\n",
    "# precondition: k <= len(df)\n",
    "def fit_k_means_clustering(df, k, stopping_dist):\n",
    "    df_cont = preprocess_df(df, 6)\n",
    "    \n",
    "    # initialize centroids\n",
    "    centroids = init_centroids((-1, 1), k, df_cont)\n",
    "    prev_centroids = None\n",
    "    clusters = None\n",
    "    \n",
    "    # iterate for an arbitrarily large number of times\n",
    "    i = 0\n",
    "    maxI = 100\n",
    "    while i < maxI:\n",
    "        i += 1\n",
    "        print('iterations: {}'.format(i))\n",
    "        \n",
    "        # keep track of previous centroids\n",
    "        prev_centroids = centroids\n",
    "        \n",
    "        clusters = []\n",
    "        \n",
    "        # loop through dataframe\n",
    "        for index in range(len(df_cont)):\n",
    "            # get track vector\n",
    "            track_array = np.array(df_cont.iloc[index].drop(['id']))\n",
    "            \n",
    "            distances = []\n",
    "            \n",
    "            # loop through centroids and compute the Euclidean distance of each centroid to the track vector\n",
    "            for labeled_centroid in centroids:\n",
    "                euclid_dist = np.linalg.norm(labeled_centroid[1] - track_array)\n",
    "                distances.append((labeled_centroid[0], euclid_dist))\n",
    "            \n",
    "            # assign track vector to the closest centroid\n",
    "            sorted_distances = sorted(distances, key=lambda x: x[1])\n",
    "            clusters.append((sorted_distances[0][0], track_array))\n",
    "        \n",
    "        centroids = []\n",
    "        \n",
    "        # loop through clusters to recompute centroids\n",
    "        for c in range(k):\n",
    "            cluster = []\n",
    "            for labeled_cluster in clusters:\n",
    "                if labeled_cluster[0] == c:\n",
    "                    cluster.append(labeled_cluster[1])\n",
    "            \n",
    "            # compute mean vector by summing all vectors in a cluster and diving by the number of vectors\n",
    "            vector_sum = np.zeros(len(cluster[0]))\n",
    "            for vector in cluster:\n",
    "                vector_sum = vector_sum + vector\n",
    "            \n",
    "            mean_vector = vector_sum/len(cluster)\n",
    "            centroids.append((c, mean_vector))\n",
    "        \n",
    "        centroid_distances = []\n",
    "        \n",
    "        # compute the Euclidean distances between the current and previous centroids\n",
    "        for c in range(k):\n",
    "            centroid_euclid_dist = np.linalg.norm(centroids[c][1] - prev_centroids[c][1])\n",
    "            centroid_distances.append(centroid_euclid_dist)\n",
    "        \n",
    "        centroid_distances = np.array(centroid_distances)\n",
    "        dist_are_less = centroid_distances < stopping_dist\n",
    "        \n",
    "        # terminate loop if all computed distances are less than stopping_dist\n",
    "        if np.all(dist_are_less):\n",
    "            break\n",
    "    \n",
    "    centroids = [centroid[1] for centroid in centroids]\n",
    "    labels = [cluster[0] for cluster in clusters]\n",
    "    \n",
    "    return {'centroids':centroids, 'labels':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "# returns a list of tuples that contain the song names and IDs of the recommended songs\n",
    "# precondition: The given track ID is in df.\n",
    "# precondition: num_tracks < len(df)\n",
    "def k_means_recommender_rand_sample(df, labels, given_track_id, num_tracks):\n",
    "    given_track_index = df[df['id']==given_track_id].index.tolist()[0]\n",
    "    given_track_label = labels[given_track_index]\n",
    "    \n",
    "    given_cluster_label_indexes = []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == given_track_label:\n",
    "            given_cluster_label_indexes.append(i)\n",
    "    \n",
    "    rng = default_rng()\n",
    "    selected_indexes = rng.integers(len(given_cluster_label_indexes), size=num_tracks)\n",
    "    \n",
    "    rec_songs = []\n",
    "    for i in selected_indexes:\n",
    "        rec_song = df.iloc[given_cluster_label_indexes[i]]\n",
    "        rec_songs.append((rec_song['name'], rec_song['id']))\n",
    "    \n",
    "    return rec_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of tuples that contain the song names and IDs of the recommended songs\n",
    "# precondition: The given track ID is in df.\n",
    "# precondition: num_tracks < len(df)\n",
    "# precondition: closeness >= 0 and closeness <= 1\n",
    "def k_means_recommender_euclid_dist(df, labels, given_track_id, num_tracks, closeness):\n",
    "    given_track_index = df[df['id']==given_track_id].index.tolist()[0]\n",
    "    given_track_label = labels[given_track_index]\n",
    "    \n",
    "    given_cluster_label_indexes = []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label == given_track_label:\n",
    "            given_cluster_label_indexes.append(i)\n",
    "    \n",
    "    selected_tracks = []\n",
    "    for i in given_cluster_label_indexes:\n",
    "        selected_tracks.append(np.array(df.iloc[i]))\n",
    "    \n",
    "    cluster_df = pd.DataFrame(selected_tracks, columns=df.columns)\n",
    "    sorted_tracks = fit_euclid_dist_recommender(cluster_df, given_track_id)\n",
    "    return euclid_dist_recommender(cluster_df, sorted_tracks, num_tracks, closeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb97706",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_k_means_clustering(df, 6, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d79d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name']=='Drag Me Down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_songs_rand = k_means_recommender_rand_sample(df, model['labels'], '2K87XMYnUMqLcX3zvtAF4G', 5)\n",
    "print(rec_songs_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d99e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_songs_euclid = k_means_recommender_euclid_dist(df, model['labels'], '2K87XMYnUMqLcX3zvtAF4G', 5, 0)\n",
    "print(rec_songs_euclid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e13be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(df, dims, labels):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for index in range(len(df)):\n",
    "        track = df.iloc[index]\n",
    "        x.append(track[dims[0]])\n",
    "        y.append(track[dims[1]])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(x, y, c=labels, cmap='rainbow')\n",
    "    plt.xlabel(dims[0])\n",
    "    plt.ylabel(dims[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07868f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat_1 in enumerate(continuous_features_cols):\n",
    "    for feat_2 in continuous_features_cols:\n",
    "        if feat_2 == feat_1:\n",
    "            continue\n",
    "        if continuous_features_cols.index(feat_2) < i:\n",
    "            continue\n",
    "        \n",
    "        plot_clusters(df, [feat_1, feat_2], model['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff16d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def fit_k_means_clustering_sk(k):\n",
    "    model = KMeans(n_clusters=k)\n",
    "    df_cont = preprocess_df(df, 6).drop('id', axis=1)\n",
    "    model.fit(df_cont)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb486e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sk = fit_k_means_clustering_sk(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f602e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_songs_rand_sk = k_means_recommender_rand_sample(df, model_sk.labels_, '2K87XMYnUMqLcX3zvtAF4G', 5)\n",
    "print(rec_songs_rand_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_songs_euclid_sk = k_means_recommender_euclid_dist(df, model_sk.labels_, '2K87XMYnUMqLcX3zvtAF4G', 5, 0)\n",
    "print(rec_songs_euclid_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat_1 in enumerate(continuous_features_cols):\n",
    "    for feat_2 in continuous_features_cols:\n",
    "        if feat_2 == feat_1:\n",
    "            continue\n",
    "        if continuous_features_cols.index(feat_2) < i:\n",
    "            continue\n",
    "        \n",
    "        plot_clusters(df, [feat_1, feat_2], model_sk.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349baa03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
